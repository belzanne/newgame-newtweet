{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database\n",
      "Table 'socialmedia-developer' already exists.\n",
      "Found 13 Twitter handles to process\n",
      "Processing Auspicious_Inc...\n",
      "Requesting data for Auspicious_Inc from https://socialblade.com/twitter/user/Auspicious_Inc\n",
      "Data scraped for Auspicious_Inc: {'followers': '624', 'following': '880', 'tweets': '298', 'created_date': 'Mar 27th, 2021'}\n",
      "Inserting/Updating data for Auspicious_Inc\n",
      "Data committed for Auspicious_Inc\n",
      "Processing cetacity...\n",
      "Requesting data for cetacity from https://socialblade.com/twitter/user/cetacity\n",
      "Data scraped for cetacity: {'followers': '873', 'following': '11', 'tweets': '92', 'created_date': 'Oct 3rd, 2023'}\n",
      "Inserting/Updating data for cetacity\n",
      "Data committed for cetacity\n",
      "Processing SasanquaGames...\n",
      "Requesting data for SasanquaGames from https://socialblade.com/twitter/user/SasanquaGames\n",
      "Data scraped for SasanquaGames: {'followers': '1,399', 'following': '1,338', 'tweets': '71', 'created_date': 'Jun 18th, 2024'}\n",
      "Inserting/Updating data for SasanquaGames\n",
      "Data committed for SasanquaGames\n",
      "Processing GladiolusTechGT...\n",
      "Requesting data for GladiolusTechGT from https://socialblade.com/twitter/user/GladiolusTechGT\n",
      "Data scraped for GladiolusTechGT: {'followers': 'N/A', 'following': 'N/A', 'tweets': 'N/A', 'created_date': 'N/A'}\n",
      "Inserting/Updating data for GladiolusTechGT\n",
      "Data committed for GladiolusTechGT\n",
      "Processing sixdotsapp...\n",
      "Requesting data for sixdotsapp from https://socialblade.com/twitter/user/sixdotsapp\n",
      "Data scraped for sixdotsapp: {'followers': 'N/A', 'following': 'N/A', 'tweets': 'N/A', 'created_date': 'N/A'}\n",
      "Inserting/Updating data for sixdotsapp\n",
      "Data committed for sixdotsapp\n",
      "Processing BeckSkylor...\n",
      "Requesting data for BeckSkylor from https://socialblade.com/twitter/user/BeckSkylor\n",
      "Data scraped for BeckSkylor: {'followers': 'N/A', 'following': 'N/A', 'tweets': 'N/A', 'created_date': 'N/A'}\n",
      "Inserting/Updating data for BeckSkylor\n",
      "Data committed for BeckSkylor\n",
      "Processing pixelcoregames...\n",
      "Requesting data for pixelcoregames from https://socialblade.com/twitter/user/pixelcoregames\n",
      "Data scraped for pixelcoregames: {'followers': '52', 'following': '8', 'tweets': '6', 'created_date': 'Jul 12th, 2024'}\n",
      "Inserting/Updating data for pixelcoregames\n",
      "Data committed for pixelcoregames\n",
      "Processing foodomina...\n",
      "Requesting data for foodomina from https://socialblade.com/twitter/user/foodomina\n",
      "Data scraped for foodomina: {'followers': '162', 'following': '176', 'tweets': '254', 'created_date': 'Jun 11th, 2022'}\n",
      "Inserting/Updating data for foodomina\n",
      "Data committed for foodomina\n",
      "Processing infinitecode_...\n",
      "Requesting data for infinitecode_ from https://socialblade.com/twitter/user/infinitecode_\n",
      "Data scraped for infinitecode_: {'followers': 'N/A', 'following': 'N/A', 'tweets': 'N/A', 'created_date': 'N/A'}\n",
      "Inserting/Updating data for infinitecode_\n",
      "Data committed for infinitecode_\n",
      "Processing DarekDoWziecia...\n",
      "Requesting data for DarekDoWziecia from https://socialblade.com/twitter/user/DarekDoWziecia\n",
      "Data scraped for DarekDoWziecia: {'followers': 'N/A', 'following': 'N/A', 'tweets': 'N/A', 'created_date': 'N/A'}\n",
      "Inserting/Updating data for DarekDoWziecia\n",
      "Data committed for DarekDoWziecia\n",
      "Processing FromScratchGS...\n",
      "Requesting data for FromScratchGS from https://socialblade.com/twitter/user/FromScratchGS\n",
      "Data scraped for FromScratchGS: {'followers': 'N/A', 'following': 'N/A', 'tweets': 'N/A', 'created_date': 'N/A'}\n",
      "Inserting/Updating data for FromScratchGS\n",
      "Data committed for FromScratchGS\n",
      "Processing ghummayda...\n",
      "Requesting data for ghummayda from https://socialblade.com/twitter/user/ghummayda\n",
      "Data scraped for ghummayda: {'followers': 'N/A', 'following': 'N/A', 'tweets': 'N/A', 'created_date': 'N/A'}\n",
      "Inserting/Updating data for ghummayda\n",
      "Data committed for ghummayda\n",
      "Processing goma_feet...\n",
      "Requesting data for goma_feet from https://socialblade.com/twitter/user/goma_feet\n",
      "Data scraped for goma_feet: {'followers': 'N/A', 'following': 'N/A', 'tweets': 'N/A', 'created_date': 'N/A'}\n",
      "Inserting/Updating data for goma_feet\n",
      "Data committed for goma_feet\n",
      "After update, found 13 rows in the database\n",
      "(2689770, '@Auspicious_Inc', '2024-07-29 18:54:49', '624', '880', '298', 'Mar 27th, 2021')\n",
      "(3046300, '@cetacity', '2024-07-29 18:54:55', '873', '11', '92', 'Oct 3rd, 2023')\n",
      "(3075040, '@SasanquaGames', '2024-07-29 18:55:01', '1,399', '1,338', '71', 'Jun 18th, 2024')\n",
      "(3093420, '@GladiolusTechGT', '2024-07-29 18:55:06', 'N/A', 'N/A', 'N/A', 'N/A')\n",
      "(3104880, '@sixdotsapp', '2024-07-29 18:55:12', 'N/A', 'N/A', 'N/A', 'N/A')\n",
      "Database update completed and connection closed.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def scrape_social_blade(handle):\n",
    "    url = f\"https://socialblade.com/twitter/user/{handle}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Requesting data for {handle} from {url}\")\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    for item in ['followers', 'following', 'tweets']:\n",
    "        element = soup.find('span', string=re.compile(item, re.IGNORECASE))\n",
    "        if element:\n",
    "            value = element.find_next('span').text.strip()\n",
    "            data[item] = value\n",
    "        else:\n",
    "            data[item] = \"N/A\"\n",
    "    \n",
    "    created_element = soup.find('span', string=re.compile(\"User Created\", re.IGNORECASE))\n",
    "    if created_element:\n",
    "        created_date = created_element.find_next('span').text.strip()\n",
    "        try:\n",
    "            data['created_date'] = datetime.strptime(created_date, \"%b %d, %Y\").strftime(\"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            data['created_date'] = created_date\n",
    "    else:\n",
    "        data['created_date'] = \"N/A\"\n",
    "    \n",
    "    print(f\"Data scraped for {handle}: {data}\")\n",
    "    return data\n",
    "\n",
    "def update_database():\n",
    "    conn = sqlite3.connect('socialmedia-developer.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    print(\"Connected to database\")\n",
    "\n",
    "    # Vérifier si la table existe\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='developer_social_media'\")\n",
    "    if not cursor.fetchone():\n",
    "        print(\"Table 'developer_social_media' does not exist. Creating it.\")\n",
    "        cursor.execute('''\n",
    "        CREATE TABLE developer_social_media (\n",
    "            game_id INTEGER,\n",
    "            twitter_handle TEXT,\n",
    "            execution_date TEXT,\n",
    "            followers_count TEXT,\n",
    "            following_count TEXT,\n",
    "            tweets_count TEXT,\n",
    "            creation_date TEXT\n",
    "        )\n",
    "        ''')\n",
    "    else:\n",
    "        print(\"Table 'socialmedia-developer' already exists.\")\n",
    "\n",
    "    # Récupérer tous les twitter_handles\n",
    "    cursor.execute(\"SELECT DISTINCT game_id, twitter_handle FROM developer_social_media WHERE twitter_handle IS NOT NULL\")\n",
    "    handles = cursor.fetchall()\n",
    "\n",
    "    print(f\"Found {len(handles)} Twitter handles to process\")\n",
    "\n",
    "    for game_id, handle in handles:\n",
    "        if handle.startswith('@'):\n",
    "            handle = handle[1:]  # Enlever le @ si présent\n",
    "        \n",
    "        print(f\"Processing {handle}...\")\n",
    "        data = scrape_social_blade(handle)\n",
    "        execution_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        print(f\"Inserting/Updating data for {handle}\")\n",
    "        cursor.execute('''\n",
    "        INSERT OR REPLACE INTO social_media_data \n",
    "        (game_id, twitter_handle, execution_date, followers_count, following_count, tweets_count, creation_date)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (game_id, '@' + handle, execution_date, data.get('followers', 'N/A'), \n",
    "              data.get('following', 'N/A'), data.get('tweets', 'N/A'), data.get('created_date', 'N/A')))\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"Data committed for {handle}\")\n",
    "        time.sleep(5)  # Pause de 5 secondes entre chaque requête\n",
    "\n",
    "    # Vérifier les données après mise à jour\n",
    "    cursor.execute(\"SELECT * FROM social_media_data\")\n",
    "    rows = cursor.fetchall()\n",
    "    print(f\"After update, found {len(rows)} rows in the database\")\n",
    "    for row in rows[:5]:  # Afficher les 5 premières lignes pour vérification\n",
    "        print(row)\n",
    "\n",
    "    conn.close()\n",
    "    print(\"Database update completed and connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    update_database()\n",
    "\n",
    "#todo : pour ne pas qu'il récupère tous les handle tous les jours, stocker derniere date d'execution et faire scrapping que pour ceux avec une date d'exeuction veille ou il y a 3 mois pour actualisation\n",
    "#faire que main.py ajoute une date quand stocke handle ? Pour tracer date rapatriement et faire les actualisationn t+3mois, +6mois etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newgame-newtweet-icRyx73a-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
