{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Configuration du logging\n",
    "logging.basicConfig(filename='smdev_update_log.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def scrape_social_blade(handle):\n",
    "    url = f\"https://socialblade.com/twitter/user/{handle}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        data = {}\n",
    "        for item in ['followers', 'following', 'tweets']:\n",
    "            element = soup.find('span', string=re.compile(item, re.IGNORECASE))\n",
    "            if element:\n",
    "                value = element.find_next('span').text.strip()\n",
    "                data[item] = int(value.replace(',', ''))\n",
    "            else:\n",
    "                data[item] = None\n",
    "        \n",
    "        created_element = soup.find('span', string=re.compile(\"User Created\", re.IGNORECASE))\n",
    "        if created_element:\n",
    "            created_date = created_element.find_next('span').text.strip()\n",
    "            data['created_date'] = parse_date(created_date)\n",
    "        else:\n",
    "            data['created_date'] = None\n",
    "        \n",
    "        logging.info(f\"Data scraped for {handle}: {data}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping data for {handle}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def parse_date(date_string):\n",
    "    months = {\n",
    "        'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06',\n",
    "        'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'\n",
    "    }\n",
    "    match = re.match(r'(\\w{3})\\s(\\d{1,2})(?:st|nd|rd|th)?,\\s(\\d{4})', date_string)\n",
    "    if match:\n",
    "        month, day, year = match.groups()\n",
    "        return f\"{year}-{months[month]}-{day.zfill(2)}\"\n",
    "    return None\n",
    "\n",
    "def update_database():\n",
    "    conn = sqlite3.connect('socialmedia-developer.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    logging.info(\"Connected to database\")\n",
    "\n",
    "    try:\n",
    "        # Assurez-vous que la table existe\n",
    "        cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS socialmedia_dev (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            add_date INTEGER,\n",
    "            game_id INTEGER,\n",
    "            twitter_handle TEXT,\n",
    "            scrap_date INTEGER,\n",
    "            followers_count INTEGER,\n",
    "            following_count INTEGER,\n",
    "            tweets_count INTEGER,\n",
    "            creation_date TEXT\n",
    "        )\n",
    "        ''')\n",
    "\n",
    "        current_timestamp = int(time.time())\n",
    "        three_months_ago = current_timestamp - (90 * 24 * 60 * 60)  # 90 jours en secondes\n",
    "\n",
    "        # Récupérer les handles qui n'ont jamais été scrapés ou qui n'ont pas été scrapés depuis plus de 3 mois\n",
    "        cursor.execute('''\n",
    "        SELECT id, game_id, twitter_handle, add_date, scrap_date\n",
    "        FROM socialmedia_dev\n",
    "        WHERE scrap_date IS NULL\n",
    "           OR (scrap_date < ? AND id IN (\n",
    "               SELECT MAX(id)\n",
    "               FROM socialmedia_dev\n",
    "               GROUP BY game_id, twitter_handle\n",
    "           ))\n",
    "        ''', (three_months_ago,))\n",
    "\n",
    "        handles_to_scrape = cursor.fetchall()\n",
    "\n",
    "        logging.info(f\"Found {len(handles_to_scrape)} Twitter handles to process\")\n",
    "\n",
    "        for row in handles_to_scrape:\n",
    "            id, game_id, handle, add_date, last_scrap_date = row\n",
    "            if handle.startswith('@'):\n",
    "                handle = handle[1:]  # Enlever le @ si présent\n",
    "            \n",
    "            logging.info(f\"Processing {handle}...\")\n",
    "            data = scrape_social_blade(handle)\n",
    "            \n",
    "            if data:\n",
    "                scrap_timestamp = current_timestamp\n",
    "                \n",
    "                # Insérer une nouvelle ligne avec les données mises à jour\n",
    "                cursor.execute('''\n",
    "                INSERT INTO socialmedia_dev \n",
    "                (game_id, twitter_handle, add_date, scrap_date, followers_count, following_count, tweets_count, creation_date)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                ''', (game_id, '@' + handle, add_date, scrap_timestamp, data.get('followers'), \n",
    "                      data.get('following'), data.get('tweets'), data.get('created_date')))\n",
    "\n",
    "                conn.commit()\n",
    "                logging.info(f\"Data committed for {handle}\")\n",
    "            else:\n",
    "                logging.warning(f\"No data scraped for {handle}, skipping update\")\n",
    "\n",
    "            time.sleep(5)  # Pause de 5 secondes entre chaque requête\n",
    "\n",
    "        # Vérifier les données après mise à jour\n",
    "        cursor.execute(\"SELECT * FROM socialmedia_dev ORDER BY scrap_date DESC LIMIT 5\")\n",
    "        rows = cursor.fetchall()\n",
    "        logging.info(\"After update, displaying the 5 most recent entries:\")\n",
    "        for row in rows:\n",
    "            logging.info(row)\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        logging.error(f\"SQLite error: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error: {str(e)}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "        logging.info(\"Database connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    update_database()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newgame-newtweet-icRyx73a-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
